\input{../common}

\begin{document}
  %<*content>
  \lesson{algebra}{148}{Dimension d'un espace vectoriel (on se limitera au cas de la dimension finie). Rang. Exemples et applications.}

  Soit $E$ un espace vectoriel sur un corps commutatif $\mathbb{K}$.

  \subsection{Espaces vectoriels de dimension finie}

  \subsubsection{Familles génératrices, familles libres}

  \reference[GOU21]{117}

  \begin{definition}
    Soit $A \subseteq E$.
    \begin{itemize}
      \item On dit que $A$ est une \textbf{partie génératrice} de $E$ si $E = \operatorname{Vect}(A)$.
      \item On dit que $A$ est une \textbf{partie libre} de $E$ si
      \[ \forall (a_i)_{i \in I} \subseteq A, \forall (\lambda_i)_{i \in I} \subseteq \mathbb{K}, \, \sum_{i \in I} \lambda_i a_i = 0 \implies \forall i \in I, \, \lambda_i = 0 \]
      (ou de manière équivalente, si aucun vecteur de $A$ n'est combinaison linéaire des autres).
      \item On dit que $A$ est une \textbf{partie liée} de $E$ si $A$ n'est pas libre.
    \end{itemize}
  \end{definition}

  \begin{example}
    Dans le $\mathbb{R}$-espace vectoriel des fonctions réelles continues, les familles suivantes sont libres :
    \begin{itemize}
      \item $(f_\lambda)$ où $\forall \lambda \in \mathbb{R}, f_\lambda : x \mapsto e^{\lambda x}$.
      \item $(g_\lambda)$ où $\forall \lambda \in \mathbb{R}, g_\lambda : x \mapsto \cos(\lambda x)$.
      \item $(h_\lambda)$ où $\forall \lambda \in \mathbb{R}, h_\lambda : x \mapsto |x - \lambda|$.
    \end{itemize}
  \end{example}

  \reference[ROM21]{357}

  \begin{proposition}[Polynômes à degrés échelonnés]
    Une famille de polynômes non nuls de $\mathbb{K}_n[X] = \{ P \in \mathbb{K}[X] \mid \deg(P) \leq n \}$ échelonnée en degré est libre dans $\mathbb{K}_n[X]$.
  \end{proposition}

  \reference[GOU20]{337}

  \begin{application}[Théorème des extrema liés]
    Soit $U$ un ouvert de $\mathbb{R}^n$ et soient $f, g_1, \dots, g_r : U \rightarrow \mathbb{R}$ des fonctions de classe $\mathcal{C}^1$. On note $\Gamma = \{ x \in U \mid g_1(x) = \dots = g_r(x) = 0 \}$. Si $f_{|\Gamma}$ admet un extremum relatif en $a \in \Gamma$ et si les formes linéaires $\mathrm{d}(g_1)_a, \dots, \mathrm{d}(g_r)_a$ sont linéairement indépendantes, alors il existe des uniques $\lambda_1, \dots, \lambda_r$ appelés \textbf{multiplicateurs de Lagrange} tels que
    \[ \mathrm{d}f_a = \lambda_1 \mathrm{d}(g_1)_a + \dots + \lambda_r \mathrm{d}(g_r)_a \]
  \end{application}

  \reference[GOU21]{117}

  \begin{definition}
    On dit que $E$ est de \textbf{dimension finie} s'il existe une partie génératrice finie de $E$. Dans le cas contraire, $E$ est dit de \textbf{dimension infinie}.
  \end{definition}

  \subsubsection{Bases}

  \begin{definition}
    Une partie libre et génératrice de $E$ est une \textbf{base} de $E$.
  \end{definition}

  \begin{example}
    \begin{itemize}
      \item La famille $(e_i)_{i \in \llbracket 1, n \rrbracket}$ (où $e_i = (0, \dots, 0, 1, 0, \dots 0)$, le $1$ se trouvant à la $i$-ième position) est une base de $\mathbb{K}^n$ appelée \textbf{base canonique} de $\mathbb{K}^n$.
      \item La famille $(X^i)_{i \in \mathbb{N}}$ est une base de $\mathbb{K}[X]$ appelée \textbf{base canonique} de $\mathbb{K}[X]$.
    \end{itemize}
  \end{example}

  \reference[ROM21]{257}

  \begin{proposition}
    Plus généralement, toute famille de polynômes non nuls de $\mathbb{K}_n[X]$ échelonnée en degré est une base de $\mathbb{K}_n[X]$.
  \end{proposition}

  \reference[GOU21]{117}

  \begin{proposition}
    Soit $B = (e_i)_{i \in I}$ une base de $E$. Alors, tout vecteur $x$ de $E$ s'écrit de manière unique $x = \sum_{i \in I} x_i e_i$ avec $\forall i \in I, \, x_i \in E$. Les $x_i$ sont les \textbf{coordonnées} de $x$ dans la base $B$.
  \end{proposition}

  \begin{theorem}
    On suppose $E$ de dimension finie. Alors pour toute partie génératrice $\mathcal{G} \subseteq E$ et toute famille libre $\mathcal{L} \subseteq \mathcal{G}$, il existe une base $B$ de $E$ telle que $\mathcal{L} \subseteq B \subseteq \mathcal{G}$.
  \end{theorem}

  \begin{corollary}
    On suppose $E$ de dimension finie.
    \begin{itemize}
      \item Il existe une base de $E$.
      \item (Théorème de la base extraite) De toute partie génératrice de $E$, on peut extraire une base de $E$.
      \item (Théorème de la base incomplète) Toute partie libre de $E$ peut-être complétée en une base de $E$.
    \end{itemize}
  \end{corollary}

  \subsubsection{Théorie de la dimension}

  \begin{theorem}
    On suppose $E$ de dimension finie. Toutes les bases de $E$ ont le même cardinal $n$. L'entier $n$ s'appelle \textbf{dimension} de $E$, noté $\dim_{\mathbb{K}}(E)$ (ou simplement $\dim(E)$ en l'absence d'ambiguïté sur le corps de base).
  \end{theorem}

  Dans toute la suite, on se limitera au cas où $E$ est de dimension finie, et on notera $n = \dim(E)$.

  \begin{proposition}
    \begin{itemize}
      \item Tout système libre de $n$ vecteurs de $E$ est une base de $E$.
      \item Tout système générateur de $n$ vecteurs de $E$ est une base de $E$.
    \end{itemize}
  \end{proposition}

  \begin{proposition}
    Soient $E_1, \dots, E_k$ des sous-espaces vectoriels de $E$. Alors,
    \[ E = E_1 \oplus \dots \oplus E_k \iff E = E_1 + \dots + E_k \text{ et } n = \sum_{i=1}^{k} \dim(E_i) \]
  \end{proposition}

  \begin{proposition}[Formule de Grassmann]
    Soient $E_1$ et $E_2$ deux sous-espaces vectoriels de $E$. Alors,
    \[ \dim(E_1 + E_2) = \dim(E_1) + \dim(E_2) - \dim(E_1 \, \cap \, E_2) \]
  \end{proposition}

  \begin{corollary}
    Soient $E_1$ et $E_2$ deux sous-espaces vectoriels de $E$. Les assertions suivantes sont équivalentes :
    \begin{enumerate}[label=(\roman*)]
      \item $E = E_1 \oplus E_2$.
      \item $\dim(E) = \dim(E_1) + \dim(E_2)$ et $E_1 \, \cap \, E_2 = \{ 0 \}$.
      \item $\dim(E) = \dim(E_1) + \dim(E_2)$ et $E = E_1 + E_2$.
    \end{enumerate}
  \end{corollary}

  \reference{240}

  \begin{example}
    \[ \mathcal{M}_n(\mathbb{K}) = \mathcal{S}_n(\mathbb{K}) \oplus \mathcal{A}_n(\mathbb{K}) \]
  \end{example}

  \subsection{Rang}

  \subsubsection{Rang d'une application linéaire}

  \reference{120}

  \begin{definition}
    Soient $E$ et $F$ deux espaces vectoriels sur $\mathbb{K}$. Soit $f \in \mathcal{L}(E, F)$. Si $\im(f)$ est de dimension finie, on appelle \textbf{rang} de $f$ l'entier $\dim(\im(f))$, noté $\rang (f)$.
  \end{definition}

  \begin{theorem}[Théorème du rang]
    Soient $E$ et $F$ deux espaces vectoriels sur $\mathbb{K}$ avec $E$ de dimension finie. Alors,
    \[ \dim(E) = \dim(\ker (f)) + \rang (f) \]
  \end{theorem}

  \begin{corollary}
    Soit $f \in \mathcal{L}(E, F)$ où $E$ et $F$ sont de même dimension finie. Alors :
    \[ f \text{ bijective} \iff f \text{ injective} \iff f \text{ surjective} \]
  \end{corollary}

  \begin{cexample}
    L'application
    \[
    \begin{array}{ccc}
      \mathbb{R}[X] &\rightarrow& \mathbb{R}[X] \\
      P &\mapsto& P'
    \end{array}
    \]
    est linéaire surjective, mais pas injective.
  \end{cexample}

  \reference{138}

  \begin{application}
    L'application
    \[
    \begin{array}{ccc}
      \mathcal{M}_n(\mathbb{K}) &\rightarrow& \mathcal{L}(\mathcal{M}_n(\mathbb{K}), \mathbb{K}) \\
      A &\mapsto& (X \mapsto \trace(AX))
    \end{array}
    \]
    est un isomorphisme.
  \end{application}

  \subsubsection{Rang d'une matrice}

  \reference{128}

  \begin{definition}
    Soit $A \in \mathcal{M}_{p,q}(\mathbb{K})$. On appelle \textbf{rang} de $A$ la dimension du sous-espace vectoriel de $\mathbb{K}^q$ engendré par les colonnes de $A$. Si $A$ est la matrice d'une application linéaire $f$, on a $\rang (A) = \rang (f)$.
  \end{definition}

  \begin{remark}
    Soit $A \in \mathcal{M}_{p,q}(\mathbb{K})$.
    \begin{itemize}
      \item $\rang(A) \leq \min(p, q)$.
      \item Si $p = q$, $A$ est inversible si et seulement si $\rang(A) = p$.
    \end{itemize}
  \end{remark}

  \begin{theorem}
    Soit $A \in \mathcal{M}_{p,q}(\mathbb{K})$. Si $A$ est de rang $r \geq 1$, alors $A$ est équivalente à
    \[ J_r =
    \begin{pmatrix}
      I_r & 0 \\
      0 & O
    \end{pmatrix}
    \]
  \end{theorem}

  \begin{corollary}
    Deux matrices $A$ et $B \in \mathcal{M}_{p,q}(\mathbb{K})$ sont équivalentes si et seulement si elles ont le même rang.
  \end{corollary}

  \begin{theorem}
    Le rang d'une matrice est le plus grand des ordres des matrices carrées inversibles extraites de cette matrice.
  \end{theorem}

  \begin{corollary}
    Le rang de toute matrice est égal au rang de sa transposée.
  \end{corollary}

  \begin{remark}
    Autrement dit, la dimension du sous-espace engendré par les vecteurs colonnes d'une matrice est égal à la dimension du sous-espace engendré par ses vecteurs lignes.
  \end{remark}

  \begin{proposition}
    On ne change pas le rang d'une matrice par opérations élémentaires.
  \end{proposition}

  \begin{example}
    On peut utiliser l'algorithme du pivot de Gauss pour trouver le rang d'une matrice. Ainsi,
    \[ \rang
    \begin{pmatrix}
      2 & 1 & 3 & -3 \\
      -1 & 2 & 1 & 4 \\
      1 & 1 & 2 & -1
    \end{pmatrix}
    = \rang
    \begin{pmatrix}
      2 & 1 & 3 & -3 \\
      0 & 1 & 1 & 1 \\
      0 & 1 & 1 & 1
    \end{pmatrix}
    = 2 \]
  \end{example}

  \subsection{Applications}

  \subsubsection{Dualité}

  Soit $E$ un espace vectoriel sur $\mathbb{K}$ de dimension finie $n$.

  \begin{definition}
    L'ensemble $E^* = \mathcal{L}(E, \mathbb{K})$ est appelé \textbf{dual} de $E$. Ses éléments sont les \textbf{formes linéaires} sur $E$.
  \end{definition}

  \begin{definition}
    Soit $B = (e_1, \dots, e_n)$ une base de $E$. Pour tout $i \in \llbracket 1, n \rrbracket$, on définit
    \[
    e_i^* : e_j \mapsto
    \begin{cases}
      1 &\text{ si } i = j \\
      0 &\text{ sinon}
    \end{cases}
    \]
    la \textbf{forme linéaire coordonnée} d'indice $i$.
  \end{definition}

  \begin{theorem}
    $B^* = (e_1^*, \dots, e_n^*)$ est une base de $E^*$ appelée \textbf{base duale} de $B$. $B$ est alors la \textbf{base antéduale} de $B^*$.
  \end{theorem}

  \begin{corollary}
    \begin{itemize}
      \item $E^*$ est de dimension finie et $\dim(E^*) = n$.
      \item $\forall \varphi \in E^*, \, \varphi = \sum_{i=1}^n \varphi(e_i) e_i^*$.
    \end{itemize}
  \end{corollary}

  \reference[ROM21]{442}

  \begin{application}[Formule de Taylor]
    On suppose $\mathbb{K}$ de caractéristique nulle. Pour tout $j \in \llbracket 0, n \rrbracket$, on définit :
    \[
      e_j : \begin{array}{ccc}
        \mathbb{K}_n[X] &\rightarrow& \mathbb{K} \\
        P &\mapsto& \frac{P^{(j)}(0)}{j!}
      \end{array}
    \]
    Alors, $(e_i)_{i \in \llbracket 0, n \rrbracket}$ est une base de $K_n[X]^*$, dont la base antéduale est $(X^i)_{i \in \llbracket 0, n \rrbracket}$.
  \end{application}

  \subsubsection{Classification des formes quadratiques}

  \reference[GOU21]{239}

  On se place sur le corps $\mathbb{K} = \mathbb{R}$.

  \begin{definition}
    Soit $\varphi : E \times E \rightarrow \mathbb{K}$ une application.
    \begin{itemize}
      \item $\varphi$ est une \textbf{forme bilinéaire} sur $E$ si $\forall x \in E, \, \varphi(x,\cdot)$ est linéaire et de même pour $\varphi(\cdot,y), \forall y \in E$. Si $B=(e_i)_{i \in \llbracket 1, n \rrbracket}$ est une base de $E$, on définit la matrice $M$ de $\varphi$ dans $B$ par $M=(\varphi(e_i,e_j))_{i,j \in \llbracket 1, n \rrbracket}$.
      \item Si de plus $\forall x, y \in E, \, \varphi(x, y) = \varphi(y, x)$, on dit que $\varphi$ est \textbf{symétrique}.
    \end{itemize}
  \end{definition}

  \begin{definition}
    On appelle \textbf{forme quadratique} sur $E$ toute application $q$ de la forme
    \[
    q :
    \begin{array}{ccc}
      E &\rightarrow& \mathbb{K} \\
      x &\mapsto& \varphi(x, x)
    \end{array}
    \]
    où $\varphi$ est une forme bilinéaire symétrique sur $E$.
  \end{definition}

  \begin{proposition}
    Soit $q$ une forme quadratique sur $E$. Il existe une unique forme bilinéaire symétrique $\varphi$ telle que pour tout $x \in E$, $q(x)=\varphi(x,x)$.
    \newpar
    $\varphi$ est alors la \textbf{forme polaire} de $q$, et on a
    \[ \forall x, y \in E, \, \varphi(x,y) = \frac{1}{2} (q(x+y) - q(x) - q(y)) \]
  \end{proposition}

  \begin{definition}
    Soit $q$ une forme quadratique sur $E$. On appelle \textbf{rang} de $q$ (noté $\rang(q)$) le rang de la matrice de sa forme polaire.
  \end{definition}

  \begin{lemma}
    Soit $\Phi$ une forme quadratique sur $E$. Il existe une base $\Phi$-orthogonale (ie. si $\varphi$ est la forme polaire de $\Phi$, une base $B$ où $\forall e, e' \in B, \, \varphi(e, e') = 0$ si $e \neq e'$).
  \end{lemma}

  \dev{loi-d-inertie-de-sylvester}

  \begin{theorem}[Loi d'inertie de Sylvester]
    Soit $\Phi$ une forme quadratique sur $E$.
    \[ \exists p, q \in \mathbb{N} \text{ et } \exists f_1, \dots, f_{p+q} \in E^* \text{ tels que } \Phi = \sum_{i=1}^p |f_i|^2 - \sum_{i=p+1}^{p+q} |f_i|^2 \]
    où les formes linéaires $f_i$ sont linéairement indépendantes et où $p + q \leq n$. De plus, ces entiers ne dépendent que de $\Phi$ et pas de la décomposition choisie.
    \newpar
    Le couple $(p,q)$ est la \textbf{signature} de $\Phi$ et le rang $\Phi$ est égal à $p+q$.
  \end{theorem}

  \begin{example}
    La signature de la forme quadratique $\Phi : (x,y,z) \mapsto x^2 - 2y^2 + xz + yz$ est $(2,1)$, donc son rang est $3$.
  \end{example}

  \subsubsection{Extensions de corps}

  \reference[GOZ]{21}

  \begin{definition}
    On appelle \textbf{extension} de $\mathbb{K}$ tout corps $\mathbb{L}$ tel qu'il existe un morphisme de corps de $\mathbb{K}$ dans $\mathbb{L}$. On notera $\mathbb{L} / \mathbb{K}$ pour signifier que $\mathbb{L}$ est une extension de $\mathbb{K}$ par la suite.
  \end{definition}

  \begin{definition}
    Soit $\mathbb{L}/\mathbb{K}$ une extension de $\mathbb{K}$. On appelle \textbf{degré} de $\mathbb{L}/\mathbb{K}$ et on note $[\mathbb{L}:\mathbb{K}]$, la dimension de $\mathbb{L}$ comme $\mathbb{K}$-espace vectoriel.
  \end{definition}

  \begin{theorem}[Base télescopique]
    Soient $\mathbb{L}/\mathbb{K}$ une extension de $\mathbb{K}$ et $E$ un espace vectoriel sur $\mathbb{L}$.
    Soient $(e_i)_{i \in I}$ une base de $E$ en tant que $\mathbb{L}$-espace vectoriel et $(\alpha_j)_{j \in J}$ une base de $\mathbb{L}$ en tant que $\mathbb{K}$-espace vectoriel.
    \newpar
    Alors $(\alpha_j e_i)_{(i,j) \in I \times J}$ est une base de $E$ en tant que $\mathbb{K}$-espace vectoriel.
  \end{theorem}

  \begin{corollary}[Multiplicativité des degrés]
    Soient $\mathbb{L}/\mathbb{K}$ une extension de $\mathbb{K}$ et $\mathbb{M}/\mathbb{L}$ une extension de $\mathbb{L}$. Alors, sont équivalentes :
    \begin{enumerate}[label=(\roman*)]
      \item $\mathbb{M}$ est un $\mathbb{K}$-espace vectoriel de dimension finie.
      \item $\mathbb{M}$ est un $\mathbb{L}$-espace vectoriel de dimension finie et $\mathbb{L}$ est un $\mathbb{K}$-espace vectoriel de dimension finie.
    \end{enumerate}
    On a alors :
    \[ \dim_{\mathbb{K}}(M) = \dim_{\mathbb{L}}(M) \dim_{\mathbb{K}}(L) \iff [\mathbb{M}:\mathbb{K}] = [\mathbb{M}:\mathbb{L}] [\mathbb{L}:\mathbb{K}] \]
  \end{corollary}

  \reference{46}

  \begin{example}
    \[ [\mathbb{Q}[i + \sqrt{2}]:\mathbb{Q}] = 4 \]
  \end{example}

  \subsubsection{Commutant}

  Soit $A \in \mathcal{M}_n(\mathbb{K})$.

  \reference[GOU21]{289}

  \begin{lemma}
    Si $\pi_A = \chi_A$, alors $A$ est cyclique :
    \[ \exists x \in \mathbb{K}^n \setminus \{ 0 \} \text{ tel que } (x, Ax, \dots, A^{n-1}x) \text{ est une base de } \mathbb{K}^n \]
  \end{lemma}

  \reference[FGN2]{160}

  \begin{notation}
    \begin{itemize}
      \item On note $\mathcal{T}_n(\mathbb{K})$ l'ensemble des matrices carrées triangulaires supérieures d'ordre $n$ à coefficients dans le corps $\mathbb{K}$.
      \item On note $\mathcal{C}(A)$ le commutant de $A$.
    \end{itemize}
  \end{notation}

  \begin{lemma}
    \[ \dim_{\mathbb{K}}(\mathcal{C}(A)) \geq n \]
  \end{lemma}

  \begin{lemma}
    Le rang de $A$ est invariant par extension de corps.
  \end{lemma}

  \dev{dimension-du-commutant}

  \begin{theorem}
    \[ \mathbb{K}[A] = \mathcal{C}(A) \iff \pi_A = \chi_A \]
  \end{theorem}
  %</content>
\end{document}
