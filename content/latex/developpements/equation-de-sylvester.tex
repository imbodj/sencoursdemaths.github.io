\input{../common}

\begin{document}
  %<*content>
  \development{algebra, analysis}{equation-de-sylvester}{Équation de Sylvester}

  \summary{On montre que l'équation $AX+XB=C$ d'inconnue $X$ admet une unique solution pour tout $C \in \mathcal{M}_n(\mathbb{C})$ et pour tout $A, B \in \mathcal{M}_n(\mathbb{C})$ dont les valeurs propres sont de partie réelle strictement négative.}

  \reference[GOU21]{200}

  \begin{lemma}
    \label{equation-de-sylvester-1}
    Soit $\Vert . \Vert$ une norme d'algèbre sur $\mathcal{M}_n(\mathbb{C})$, et soit $A \in \mathcal{M}_n(\mathbb{C})$ une matrice dont les valeurs propres sont de partie réelle strictement négative. Alors il existe une fonction polynômiale $P : \mathbb{R} \rightarrow \mathbb{R}$ et $\lambda > 0$ tels que $\Vert e^{tA} \Vert \leq e^{- \lambda t} P(t)$.
  \end{lemma}

  \begin{proof}
    On fait la décomposition de Dunford de $A$ : $A = D+N$. Comme $D$ et $N$ commutent, on a $e^{tA} = e^{tD} e^{tN}$. Soient $P$ la matrice de passage donnée par la base de diagonalisation de $D$ et $\lambda_1, \dots, \lambda_n$ ses valeurs propres. En notant $\VERT . \VERT$ la norme subordonnée à $\Vert . \Vert_\infty$ sur $\mathbb{C}^n$, on a $\forall t \geq 0$,
    \begin{align*}
      \VERT e^{tD} \VERT &= \VERT e^{tP \operatorname{Diag}(\lambda_1, \dots, \lambda_n) P^{-1}} \VERT \\
      & = \VERT P e^{t \operatorname{Diag}(\lambda_1, \dots, \lambda_n)} P^{-1} \VERT \\
      & \leq \underbrace{\VERT P \VERT \VERT P^{-1} \VERT}_{= \alpha} \sup_{\Vert x \Vert_\infty = 1} \Vert \operatorname{Diag}(e^{t \lambda_1}, \dots, e^{t \lambda_n}) x \Vert_{\infty} \\
      & \leq \alpha \sup_{i \in \llbracket 1, n \rrbracket} \vert e^{t\lambda_i} \vert \\
      & \leq \alpha e^{-\lambda t}
    \end{align*}
    où $\lambda > 0$ par hypothèse. En dimension finie, toutes les normes sont équivalentes, donc il existe $\beta > 0$ tel que $\VERT e^{tD} \VERT \leq \beta e^{- \lambda t}$.
    \newpar
    Pour conclure, en notant $r$ l'indice de nilpotence de $N$,
    \begin{align*}
      \Vert e^{tA} \Vert & \leq \Vert e^{tD} \Vert \Vert e^{tN} \Vert \\
      & \leq e^{- \lambda t} \underbrace{\sum_{k=0}^{r-1} \beta \frac{\Vert N \Vert^k t^k}{k}}_{= P(t)}
    \end{align*}
  \end{proof}

  \reference[I-P]{177}

  \begin{theorem}[Équation de Sylvester]
    Soient $A$ et $B \in \mathcal{M}_n(\mathbb{C})$ deux matrices dont les valeurs propres sont de partie réelle strictement négative. Alors pour tout $C \in \mathcal{M}_n(\mathbb{C})$, l'équation $AX + XB = C$ admet une unique solution $X$ dans $\mathcal{M}_n(\mathbb{C})$.
  \end{theorem}

  \begin{proof}
    Comme l'application $\varphi : X \mapsto AX + XB$ est un endomorphisme de $\mathcal{M}_n(\mathbb{C})$, qui est un espace vectoriel de dimension finie, il suffit de montrer qu'elle est surjective pour obtenir l'injectivité (et donc l'unicité de la solution). Soit $C \in \mathcal{M}_n(\mathbb{C})$. On considère le problème de Cauchy suivant d'inconnue $Y : \mathbb{R} \rightarrow \mathcal{M}_n(\mathbb{C})$ :
    \[ \begin{cases} Y' = AY + YB \\ Y(0) = C \end{cases} \tag{$E$} \]
    Il s'agit d'une équation différentielle linéaire à coefficients constants (on peut voir cela notamment en calculant les produits $AY$ et $YB$ et en effectuant la somme ; l'égalité matricielle avec $Y'$ donnant le système d'équations voulu). D'après le théorème de Cauchy-Lipschitz linéaire, $(E)$ admet une unique solution définie sur $\mathbb{R}$ tout entier, que l'on note $Y$.
    \newpar
    On vérifie que la solution est définie $\forall t \in \mathbb{R}$ par $Y(t) = \exp(tA) C \exp(tB)$. En effet pour tout $t \in \mathbb{R}$, on a :
    \[ Y'(t) = A \exp(tA) C \exp(tB) + \exp(tA) CB \exp(tB) = AY + YB \]
    car toute matrice $M$ commute avec son exponentielle (puisque $\exp(M)$ est limite d'un polynôme en $M$) et donc $M$ commute aussi avec $\exp(tM)$ pour tout $t \in \mathbb{R}$.
    \newpar
    On va maintenant montrer que $X = - \int_{0}^{+\infty} Y(s) \, \mathrm{d}s$ est la solution de l'équation de Sylvester. Pour tout $t \geq 0$, on intègre $Y'$ entre $0$ et $t$ pour obtenir :
    \[ Y(t) - C = \int_0^t Y'(s) \, \mathrm{d}s = A \times \int_0^t Y(s) \, \mathrm{d}s + \int_0^t Y(s) \, \mathrm{d}s \times B \]
    Il ne reste donc plus qu'à montrer que $Y(t) \longrightarrow 0$ et que $Y$ est intégrable pour conclure. Par le \cref{equation-de-sylvester-1}, il existe $\lambda_1, \lambda_2 > 0$ et $P_1, P_2 : \mathbb{R} \rightarrow \mathbb{R}$ polynômiales tels que $\Vert e^{tA} \Vert \leq e^{- \lambda_1 t} P_1(t)$ et $\Vert e^{tB} \Vert \leq e^{-\lambda_2 t} P_2(t)$ pour tout $t \geq 0$. Ainsi, en posant $\lambda = \max(\lambda_1, \lambda_2)$ et $P = P_1 P_2$, comme $\Vert . \Vert$ est une norme d'algèbre :
    \[ \Vert Y(t) \Vert = \Vert e^{tA} C e^{tB} \Vert \leq \Vert C \Vert P(t) e^{-2 \lambda t} \]
    En particulier, on a bien $Y(t) \longrightarrow 0$. De plus, comme $\Vert C \Vert P(t) e^{-2 \lambda t}$ est intégrable sur $[0, +\infty[$ et domine $\Vert Y(t) \Vert$, alors $Y$ est aussi intégrable $[0, +\infty[$. Finalement, en faisant $t \longrightarrow +\infty$, on obtient :
    \[ -C = A \times \int_{0}^{+\infty} Y(s) \, \mathrm{d}s + \int_{0}^{+\infty} Y(s) \, \mathrm{d}s \times B \]
    Donc $\varphi(X) = C$ : $\varphi$ est surjective et $X$ est bien la solution de l'équation de Sylvester.
  \end{proof}

  \reference[GOU21]{189}

  \begin{remark}
    Pour dire que toute matrice $M$ commute avec $\exp(M)$, on aurait simplement pu dire que $\exp(M)$ est un polynôme en $M$ ie. $\forall M \in \mathcal{M}_n(\mathbb{C})$, $\exists P \in \mathbb{C}[X]$ tel que $\exp(M) = P(M)$.
  \end{remark}

  \begin{proof}
    Soit $M \in \mathcal{M}_n(\mathbb{C})$. L'ensemble $\mathbb{C}[M] = \{ P(M) \mid P \in \mathbb{C}[X] \}$ est un sous-espace vectoriel de $\mathcal{M}_n(\mathbb{C})$ qui est de dimension finie, donc $\mathbb{C}[M]$ l'est aussi et est en particulier fermé.
    \newpar
    Pour tout $n \in \mathbb{N}$, on pose $P_n = \sum_{k=0}^n \frac{M^k}{k!} \in \mathbb{C}[M]$ de sorte que $P_n \longrightarrow_{n \rightarrow +\infty} \exp(M)$. Comme $\mathbb{C}[M]$ est fermé, on en déduit que $\exp(M) \in \mathbb{C}[M]$. Donc $\exists P \in \mathbb{C}[X]$ tel que $\exp(M) = P(M)$.
  \end{proof}
  %</content>
\end{document}
