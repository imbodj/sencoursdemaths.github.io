\input{../common}

\begin{document}
  %<*content>
  \lesson{algebra}{153}{Valeurs propres, vecteurs propres. Calculs exacts ou approchés d'éléments propres. Applications.}

  \subsection{Spectre d'un endomorphisme}

  Soit $E$ un espace vectoriel sur un corps $\mathbb{K}$ de dimension finie $n$. Soit $u \in \mathcal{L}(E)$ un endomorphisme de $E$.

  \subsubsection{Valeurs propres, vecteurs propres}

  \reference[GOU21]{171}

  \begin{definition}
    Soit $\lambda \in \mathbb{K}$.
    \begin{itemize}
      \item On dit que $\lambda$ est \textbf{valeur propre} de $u$ si $u - \lambda \operatorname{id}_E$ est non injective.
      \item Un vecteur $x \neq 0$ tel que $u(x) = \lambda x$ est un \textbf{vecteur propre} de $u$ associé à la valeur propre $\lambda$.
      \item $E_\lambda = \ker(u - \lambda \operatorname{id}_E)$ est le \textbf{sous-espace propre} associé à la valeur propre $\lambda$.
      \item L'ensemble des valeurs propres de $u$ est appelé \textbf{spectre} de $u$. On le note $\operatorname{Sp}(u)$.
    \end{itemize}
  \end{definition}

  \begin{remark}
    \begin{itemize}
      \item $0$ est valeur propre de $u$ si et seulement si $\ker(f) \neq \{ 0 \}$.
      \item On peut définir de la même manière les mêmes notions pour une matrice de $\mathcal{M}_n(\mathbb{K})$ (une valeur est propre pour une matrice si et seulement si elle l'est pour l'endomorphisme associé). On reprendra les mêmes notations.
      \item Les sous-espaces $E_\lambda$ sont stables par $u$ pour toute valeur propre $\lambda$.
    \end{itemize}
  \end{remark}

  \begin{example}
    $\begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix}$ est vecteur propre de $\begin{pmatrix} 0 & 2 & -1 \\ 3 & -2 & 0 \\ -2 & 2 & 1 \end{pmatrix}$ associé à la valeur propre $1$.
  \end{example}

  \begin{theorem}
    Soient $\lambda_1, \dots, \lambda_k$ des valeurs propres de $u$, distinctes deux à deux. Alors les sous-espaces propres $E_{\lambda_1}, \dots, E_{\lambda_k}$ sont en somme directe.
  \end{theorem}

  \reference[ROM21]{604}

  \begin{theorem}
    Soit $P \in \mathbb{K}[X]$. Pour tout valeur propre $\lambda$ de $u$, $P(\lambda)$ est une valeur propre de $P(u)$. Si le corps $\mathbb{K}$ est algébriquement clos, on a alors
    \[ \operatorname{Sp}(P(u)) = \{ P(\lambda) \mid \lambda \in \operatorname{Sp}(u) \} \]
  \end{theorem}

  \begin{cexample}
    Pour $A = \begin{pmatrix} 0 & -1 \\ 1 & 0 \end{pmatrix} \in \mathcal{M}_2(\mathbb{R})$ et $P = X^2$, on a $A^2 = -I_2$ et $\operatorname{Sp}(A) = \emptyset$.
  \end{cexample}

  \subsubsection{Polynôme caractéristique}

  \reference{644}

  \begin{proposition}
    En notant $\chi_u = \det(X \operatorname{id}_E - u)$,
    \[ \operatorname{Sp}(u) = \{ \lambda \in \mathbb{K} \mid \chi_u(\lambda) = 0 \} \]
  \end{proposition}

  \begin{definition}
    Le polynôme $\chi_u$ précédent est appelé \textbf{polynôme caractéristique} de $u$.
  \end{definition}

  \begin{remark}
    On peut définir la même notion pour une matrice $A \in \mathcal{M}_n(\mathbb{K})$, ces deux notions coïncidant bien si $A$ est la matrice de $u$ dans une base quelconque de $E$.
  \end{remark}

  \begin{example}
    Pour $A = \begin{pmatrix} a & b \\ c & d \end{pmatrix} \in \mathcal{M}_2(\mathbb{K})$, on a $\chi_A = X^2 - \trace(A)X + \det(A)$.
  \end{example}

  \begin{proposition}
    Soit $\lambda$ une valeur propre de $u$ de multiplicité $\alpha$ en tant que racine de $\chi_u$. Alors,
    \[ \dim(E_\lambda) \in \llbracket 1, \alpha \rrbracket \]
  \end{proposition}

  \reference[GOU21]{172}

  \begin{proposition}
    \begin{enumerate}[label=(\roman*)]
      \item Le polynôme caractéristique est un invariant de similitude.
      \item Soit $A \in \mathcal{M}_n(\mathbb{K})$. On note $\chi_A = \sum_{k=0}^n a_k X^k$. Alors, $a_0 = \det(A)$ et $a_{n-1} = \trace(A)$ (à un signe près).
    \end{enumerate}
  \end{proposition}

  \reference{153}

  \begin{lemma}[Déterminant circulant]
    \label{suite-de-polygones-1}
    Soient $n \in \mathbb{N}^*$ et $a_1, \dots, a_n \in \mathbb{C}$. On pose $\omega = e^{\frac{2i\pi}{n}}$. Alors
    \[ \begin{vmatrix} a_0 & a_1 & \dots & a_{n-1} \\ a_{n-1} & a_0 & \dots & a_{n-2}\\ \vdots & \vdots & \ddots & \vdots \\ a_1 & a_2 & \dots & a_0 \end{vmatrix} = \prod_{j=0}^{n-1} P(\omega^j) \]
    où $P = \sum_{k=0}^{n-1} a_k X^k$.
  \end{lemma}

  \reference[I-P]{389}
  \dev{suite-de-polygones}

  \begin{application}[Suite de polygones]
    Soit $P_0$ un polygone dont les sommets sont $\{ z_{0,1}, \dots, z_{0,n} \}$. On définit la suite de polygones $(P_k)$ par récurrence en disant que, pour tout $k \in \mathbb{N}^*$, les sommets de $P_{k+1}$ sont les milieux des arêtes de $P_k$.
    \newpar
    Alors la suite $(P_k)$ converge vers l'isobarycentre de $P_0$.
  \end{application}

  \subsubsection{Polynôme minimal}

  \reference[ROM21]{604}

  \begin{lemma}
    \begin{enumerate}[label=(\roman*)]
      \item $\mathrm{Ann}(u) = \{ P \in \mathbb{K}[X] \mid P(u) = 0 \}$ est un sous-ensemble de $\mathbb{K}[u]$ non réduit au polynôme nul.
      \item $\mathrm{Ann}(u)$ est le noyau de $P \mapsto P(u)$ : c'est un idéal de $\mathbb{K}[u]$.
      \item Il existe un unique polynôme unitaire engendrant cet idéal.
    \end{enumerate}
  \end{lemma}

  \begin{definition}
    On appelle \textbf{idéal annulateur} de $u$ l'idéal $\mathrm{Ann}(u)$. Le polynôme unitaire générateur est noté $\pi_u$ et est appelé \textbf{polynôme minimal} de $u$.
  \end{definition}

  \begin{remark}
    \begin{itemize}
      \item $\pi_u$ est le polynôme unitaire de plus petit degré annulant $u$.
      \item Si $A \in \mathcal{M}_n(\mathbb{K})$ est la matrice de $u$ dans une base de $E$, on a $\mathrm{Ann}(u) = \mathrm{Ann}(A)$ et $\pi_u = \pi_A$.
    \end{itemize}
  \end{remark}

  \begin{example}
    Un endomorphisme est nilpotent d'indice $q$ si et seulement si son polynôme minimal est $X^q$.
  \end{example}

  \begin{proposition}
    Soit $F$ un sous-espace vectoriel de $E$ stable par $u$. Alors, le polynôme minimal de l'endomorphisme $u_{|F} : F \rightarrow F$ divise $\pi_u$.
  \end{proposition}

  \begin{proposition}
    \begin{enumerate}[label=(\roman*)]
      \item Les valeurs propres de $u$ sont racines de tout polynôme annulateur.
      \item Les valeurs propres de $u$ sont exactement les racines de $\pi_u$.
    \end{enumerate}
  \end{proposition}

  \reference[GOU21]{186}

  \begin{remark}
    $\pi_u$ et $\chi_u$ partagent dont les mêmes racines.
  \end{remark}

  \reference[ROM21]{607}

  \begin{theorem}[Cayley-Hamilton]
    \[ \pi_u \mid \chi_u \]
  \end{theorem}

  \begin{corollary}
    \[ \dim(\mathbb{K}[u]) \leq n \]
  \end{corollary}

  \subsection{Localisation}

  Soit $A = (a_{i,j})_{i, j \in \llbracket 1, n \rrbracket} \in \mathcal{M}_n(\mathbb{C})$.

  \subsubsection{Disques de Gerschgörin}

  \reference{650}

  \begin{notation}
    On note :
    \begin{itemize}
      \item Pour tout $i \in \llbracket 1, n \rrbracket$, $L_i = \sum_{\substack{j=1 \\ j \neq i}}^n \vert a_{i,j} \vert$ et $L = \max_{i \in \llbracket 1, n \rrbracket} \{ L_i + \vert a_{i,i} \vert \}$.
      \item Pour tout $j \in \llbracket 1, n \rrbracket$, $C_j = \sum_{\substack{i=1 \\ i \neq j}}^n \vert a_{i,j} \vert$ et $C = \max_{j \in \llbracket 1, n \rrbracket} \{ C_j + \vert a_{j,j} \vert \}$.
    \end{itemize}
  \end{notation}

  \begin{theorem}[Gerschgörin-Hadamard]
    \label{153-1}
    Soit $\lambda \in \mathbb{C}$ une valeur propre de $A$. Alors, il existe $i \in \llbracket 1, n \rrbracket$ tel que $\vert \lambda - a_{i,i} \vert \leq L_i$.
  \end{theorem}

  \reference[FGN2]{189}

  \begin{remark}
    Ainsi,
    \[ \operatorname{Sp}(A) \subseteq \bigcup_{i=1}^n \{ z \in \mathbb{C} \mid \vert z - a_{i,i} \vert \leq L_i \} \]
    Les disques de cette réunion sont appelés disques de Gerschgörin.
  \end{remark}

  \reference[ROM21]{672}

  \begin{example}
    Soient $a, b \in \mathbb{R}^2$. On pose
    \[
      A(a,b) =
       \begin{pmatrix}
         a & b & 0 & \dots & 0 \\
         b & a & b & \ddots & \vdots \\
         0 & \ddots & \ddots & \ddots & 0 \\
         \vdots & \ddots & b & a & b \\
         0 & \dots & 0 & b & a
       \end{pmatrix}
     \]
     Alors,
     \[ \operatorname{Sp}(A(a,b)) = \left\{ a + 2b \cos \left( \frac{k \pi}{n+1} \right) \mid k \in \llbracket 1, n \rrbracket \right\} \]
  \end{example}

  \begin{example}
    Soit
    \[
      A =
      \begin{pmatrix}
        1 & 0 & \dots & 0 & -1 \\
        -1 & 1 & 0 & \dots & 0 \\
        0 & \ddots & \ddots & \ddots & \vdots \\
        \vdots & \ddots & -1 & 1 & 0 \\
        0 & \dots & 0 & -1 & 1
      \end{pmatrix}
    \]
    Alors,
    \[ \operatorname{Sp}(\tr{A}A) = \left\{ 4 \sin \left( \frac{k \pi}{n} \right)^2 \mid k \in \llbracket 0, n-1 \rrbracket \right\} \]
  \end{example}

  \reference{651}

  \begin{corollary}
    Pour toute valeur propre $\lambda \in \mathbb{C}$ de $A$, on a
    \[ \lambda \leq \min(L,C) \]
  \end{corollary}

  \begin{corollary}
    On suppose $A$ à diagonale strictement dominante (ie. $\forall i \in \llbracket 1, n \rrbracket$, $\vert a_{i,i} \vert > \sum_{\substack{j=1 \\ j \neq i}}^n \vert a_{i,j} \vert$). Alors, $A$ est inversible.
  \end{corollary}

  \begin{theorem}[Ostrowski]
    Pour tout $\alpha \in [0,1]$ et toute valeur propre $\lambda \in \mathbb{C}$ de $A$, il existe $i \in \llbracket 1, n \rrbracket$ tel que
    \[ \vert \lambda - a_{i,i} \vert \leq L_i^{\alpha} C_i^{1-\alpha} \]
  \end{theorem}

  \begin{remark}
    C'est une généralisation du \cref{153-1} : pour $\alpha = 1$, on retrouve l'énoncé correspondant.
  \end{remark}

  \begin{corollary}
    Pour toute valeur propre $\lambda \in \mathbb{C}$ de $A$, il existe $i \in \llbracket 1, n \rrbracket$ tel que
    \[ \vert \lambda \vert^2 \leq (L_i + \vert a_{i,i} \vert) (C_i + \vert a_{i,i} \vert) \]
  \end{corollary}

  \subsubsection{Utilisation du rayon spectral}

  \begin{notation}
    À toute norme $\Vert . \Vert$ sur $\mathbb{C}^n$, on associe la norme matricielle
    \[ \VERT . \VERT : M \mapsto \sup_{x \in \mathbb{C}^n \setminus \{ 0 \}} \frac{\Vert Mx \Vert}{\Vert x \Vert} \]
  \end{notation}

  \begin{definition}
    Le \textbf{rayon spectral} de $A$, noté $\rho(A)$ est défini par
    \[ \rho(A) = \max_{\lambda \in \operatorname{Sp}(A)} \vert \lambda \vert \]
  \end{definition}

  \begin{theorem}
    On a
    \[ \VERT A \VERT_2 = \sqrt{\VERT A^* A \VERT_2} = \sqrt{\rho(A^* A)} \]
    où $\VERT . \VERT_2$ est la norme matricielle associée à la norme euclidienne sur $\mathbb{C}^n$ et $A^*$ est la transconjuguée de $A$.
  \end{theorem}

  \begin{theorem}
    \begin{enumerate}[label=(\roman*)]
      \item On a $\rho(A) \leq \VERT A \VERT$ pour toute norme matricielle $\VERT . \VERT$ induite par une norme vectorielle.
      \item $\rho(A) = \inf_{\VERT . \VERT \in \mathcal{N}} \VERT A \VERT$ où $\mathcal{N}$ désigne l'ensemble de toutes les normes matricielles induites par une norme vectorielle.
    \end{enumerate}
  \end{theorem}

  \reference[GOU21]{203}
  \dev{decomposition-de-dunford}

  \begin{theorem}[Décomposition de Dunford]
    Soit $f \in \mathcal{E}$ un endomorphisme tel que son polynôme minimal $\pi_f$ soit scindé sur $\mathbb{K}$. Alors il existe un unique couple d'endomorphismes $(d, n)$ tel que :
    \begin{itemize}
      \item $f = d + n$.
      \item $d$ est diagonalisable et $n$ est nilpotent.
      \item $d \circ n = n \circ d$.
    \end{itemize}
  \end{theorem}

  \reference[ROM21]{660}

  \begin{corollary}[Théorème de Gelfand]
    Soit $\Vert . \Vert$ une norme sur $\mathcal{M}_n(\mathbb{C})$. Alors,
    \[ \rho(A) = \lim_{k \rightarrow +\infty} \Vert A^k \Vert^{\frac{1}{k}} \]
  \end{corollary}

  \begin{proposition}
    Les conditions suivantes sont équivalentes.
    \begin{enumerate}[label=(\roman*)]
      \item $\lim_{k \rightarrow +\infty} A^k = 0$.
      \item Pour toute valeur initiale $x_0 \in \mathbb{C}^n$, la suite définie par récurrence pour tout $k \in \mathbb{N}$ par $x_{k+1} = A x_k$, converge vers le vecteur nul.
      \item $\rho(A) < 1$.
      \item Il existe au moins une norme matricielle $\VERT . \VERT$ induite par une norme vectorielle telle que $\VERT A \VERT < 1$.
    \end{enumerate}
  \end{proposition}

  \subsection{Approximation}

  Soit $A = (a_{i,j})_{i, j \in \llbracket 1, n \rrbracket} \in \mathcal{M}_n(\mathbb{R})$.

  \reference[ROM19-2]{210}

  \begin{theorem}
    On suppose que la valeur propre de $A$ de module maximum est unique. On la note $\lambda_1$. Elle est alors réelle est simple, l'espace propre associé est une droite vectorielle et on a
    \[ \mathbb{R}^n = \ker(A-\lambda_1 I_n) \oplus \im(A-\lambda_1 I_n) \]
  \end{theorem}

  On suppose pour la suite que la valeur propre de $A$ de module maximum est unique. On la note $\lambda_1$.

  \begin{notation}
    On note et on définit :
    \begin{itemize}
      \item $E_1 = \ker(A-\lambda_1 I_n)$ et $F_1 = \im(A-\lambda_1 I_n)$.
      \item $x_0 = e_1 + f_1$ avec $e_1 \in E_1 \setminus \{ 0 \}$ et $f_1 \in F_1$.
      \item $\forall k \in \mathbb{N}, \, x_{k+1} = \frac{1}{\Vert A x_k \Vert} a_k$ avec $\Vert . \Vert$ norme quelconque sur $\mathbb{R}^n$.
      \item Pour tout $j \in \llbracket 1,n \rrbracket$, on note $e_{1,j}$ la $j$-ième composante du vecteur $e_1$, $x_{k,j}$ celle de $x_k$ et $(Ax_k)_j$ celle de $Ax_k$.
    \end{itemize}
  \end{notation}

  \begin{theorem}[Méthode la puissance itérée]
    On a :
    \begin{enumerate}[label=(\roman*)]
      \item $\lim_{k \rightarrow +\infty} \Vert A x_k \Vert = \vert \lambda_1 \vert = \rho(A)$.
      \item $\lim_{k \rightarrow +\infty} x_{2k} = v_1$ où $v_1$ est un vecteur propre non nul associé à la valeur propre $\lambda_1$.
      \item $\lim_{k \rightarrow +\infty} x_{2k+1} = \operatorname{signe}(\lambda_1) v_1$.
      \item Pour tout $j \in \llbracket 1,n \rrbracket$, tel que $e_{1,j} \neq 0$,
      \[ \lim_{k \rightarrow +\infty} \frac{(A x_k)_j}{x_{k,j}} = \lambda_1 \]
    \end{enumerate}
  \end{theorem}

  \begin{remark}
    \begin{itemize}
      \item Si $A$ est inversible, la méthode précédente appliquée à $A^{-1}$ permet de calculer la valeur propre de plus petit module de $A$ (quand cette dernière est unique).
      \item En notant $e_1$ un vecteur propre de $A$ associé à la valeur propre $\lambda_1$ de norme euclidienne égale à $1$, les valeurs propres de la matrice $B = A - \lambda_1 e_1 \tr{e_1}$ sont $0, \lambda_2, \dots, \lambda_n$. On pourra alors appliquer la méthode à $B$.
    \end{itemize}
  \end{remark}

  \newpage
  \section*{Annexes}

  \reference[I-P]{389}

  \begin{figure}[h]
    \begin{center}
      \begin{tikzpicture}
        \coordinate (A) at (0:3);
        \coordinate (B) at (72:3);
        \coordinate (C) at (2*72:3);
        \coordinate (D) at (3*72:3);
        \coordinate (E) at (4*72:3);
        \coordinate (F) at (A);
        \foreach \i in {0,...,10} {
          \draw(A) node {$\bullet$};
          \draw(B) node {$\bullet$};
          \draw(C) node {$\bullet$};
          \draw(D) node {$\bullet$};
          \draw(E) node {$\bullet$};
          \draw[fill=cyan!60, fill opacity=0.2](A) -- (B) -- (C) -- (D) -- (E) -- (A);
          \coordinate (A) at ($(A)!0.5!(B)$);
          \coordinate (B) at ($(B)!0.5!(C)$);
          \coordinate (C) at ($(C)!0.5!(D)$);
          \coordinate (D) at ($(D)!0.5!(E)$);
          \coordinate (E) at ($(E)!0.5!(F)$);
          \coordinate (F) at (A);
        }
      \end{tikzpicture}
    \end{center}
    \caption{La suite de polygones.}
  \end{figure}
  %</content>
\end{document}
